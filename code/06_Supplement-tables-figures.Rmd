---
title: "Tables and Figures - Supplement A, B and C"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: pdf_document
---


This document contains the tables and figures from Supplement A, B and C for the project "Heterogeneity in direct replications in psychology and its association with effect size". This file can be found at: osf.io/bm2wa/?view_only=e6639d8d4f924739a7310782fbbb4e06

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
Sys.setlocale("LC_TIME", "English" ) #to print date in YAML in English
```

```{r load packages, data and source functions}
if(!require(readr)){install.packages("readr")}
if(!require(metafor)){install.packages("metafor")}
if(!require(dplyr)){install.packages("dplyr")}
if(!require(purrr)){install.packages("purrr")}
if(!require(kableExtra)){install.packages("kablExtra")}
if(!require(ggplot2)){install.packages("ggplot2")}
if(!require(cowplot)){install.packages("cowplot")}
if(!require(ggrepel)){install.packages("ggrepel")}
if(!require(boot)){install.packages("boot")}


library(readr) #To load data
library(dplyr) #For data transformation
library(purrr) #For data iteration
library(metafor) #To run meta-analyses
library(ggplot2) #plotting figures
library(cowplot) #combine plots
library(ggrepel) #easy labels for plots (supplement A identification of points)
library(kableExtra) #create fancy pdf tables
library(boot) #Bootstrap confidence intervals for correlations

dat <- read_csv("../data/collated_summary_data.csv")

source("03_helper_functions_tables_figures.r") #Load functions to prep data for figures
```

# Supplement A

```{r a-plot-prep, cache = TRUE}
res <- dat %>%
  split(.$effect) %>%  #separate by effect, necessary step otherwise the function is applied overall
  map_dfr(est_heterogen_smd_raw, .id = "effect") #apply function, rbind results into dataframe ('dfr'), make sure purrr is up to date

het <- dat %>%
  select(rp, Site, effect, effect_type) %>%
  group_by(rp, effect) %>%
  summarize(effect_type = unique(effect_type),
            k = n_distinct(Site)) %>%
  left_join(res) %>%
  mutate(effect_type = recode(effect_type,
                              d = "SMD.",
                              'Raw mean difference' = "MD",
                              'Risk difference' = "RD")) %>%
  ungroup()

a <- het %>% filter(rp == "ML1" & !effect %in% c('Allowed vs. forbidden', 'Gain vs. loss framing','Norm of reciprocity', 'Low vs. high category scales') & effect_type == "SMD.")
```


```{r a-plot, cache = FALSE}
a_plot <- ggplot(a, aes(x = s_I2, y = sqrt(tau2))) + geom_point() + ggtitle("SMD (untransformed)") +
  scale_x_continuous(name = expression(paste(italic(I)^2, " Index"))) +
  scale_y_continuous(name = "Tau")

```


```{r point-biserial, cache = TRUE}
#Transform effect sizes to point-biserial correlations (pearson's correlations left as is)
#estimate tau2 for correlations
#'transform_MA' and 'summarizer' are sourced functions
res2 <- dat %>%
  filter(rp == "ML1" & !effect %in% c('Allowed vs. forbidden', 'Gain vs. loss framing','Norm of reciprocity', 'Low vs. high category scales') & effect_type == "d") %>%
  split(.$effect) %>%  #separate by effect, necessary step otherwise the function is applied overall
  map(transform_MA) %>% #
  map_dfr(summarizer, .id = "effect")


b <- select(a, effect, tau2) %>%
  left_join(select(res2, effect, tau2), by = "effect") #add point-biserial transformation tau2 to untransformed

```


```{r b-plot}
b_plot <- ggplot(b, aes(x = sqrt(tau2.x), y = sqrt(tau2.y))) +
  geom_point() +
  ggtitle("SMD vs. Point biserial") +
  scale_x_continuous(name = "Tau (SMD)") +
  scale_y_continuous(name = "Tau (Point-biserial r)")

```

```{r fisher-transformed}
res3 <- dat %>%
  filter(rp == "ML1" & !effect %in% c('Allowed vs. forbidden', 'Gain vs. loss framing','Norm of reciprocity', 'Low vs. high category scales') & effect_type == "d") %>%
  split(.$effect) %>%  #separate by effect, necessary step otherwise the function is applied overall
  map(transform_MA, fisher = TRUE) %>% #Fisher-transformed
  map_dfr(summarizer, .id = "effect")


d <- select(a, effect, tau2) %>%
  left_join(select(res3, effect, tau2), by = "effect") #add fisher-transformed point-biserial transformation tau2 to untransformed
```

```{r c-plot}
c_plot <- ggplot(d, aes(x = sqrt(tau2.x), y = sqrt(tau2.y))) +
  geom_point() +
  ggtitle(expression(bold(paste("SMD vs. Fisher's ", italic(z))))) +
  scale_x_continuous(name = "Tau (SMD)") +
  scale_y_continuous(name = expression(paste("Tau (Fisher's ", italic(z), ")")))
```


```{r combine-plots, fig.width = 6, fig.asp = 1.3}

cowplot::plot_grid(a_plot, b_plot, c_plot, ncol = 1, labels = "AUTO")

# ggsave("../figures/Figure-S1.png", dpi = 600, width = 6, height = 7.8)
```

_Figure S1A_ Association between estimates of $\tau$ and $I^2$ after and before standardized mean differences (SMD) effects were transformed into point-biserial correlations for all effects reported as SMDs in Many Labs 1. Panel A shows the association between estimates of $\tau$ and $I^2$ without transformation when using the meta-analytic specification of the original authors (see main text). Panel B shows the association between estimates of $\tau$ for the same effects before and after transformation to point-biserial correlations. Panel C shows the association between estimates of $\tau$ for the same effects before and after transformation to point-biserial correlations and subsequently to Fisher's _z_.

```{r text-results, eval = FALSE}
#Not printed if knitting the document.

#to find out which point is which effect in Panel B. 
b_plot + ggrepel::geom_label_repel(data = b, aes(label = effect))

#Examine effects of larger effect size on transformation to point-biserial
transform_d_to_r(c(0, 0.1, 1, 1.1, 2, 2.1), n1 = 100, n2 = 100) #sourced function

#to find out which point is which effect in Panel C. 
c_plot + ggrepel::geom_label_repel(data = d, aes(label = effect))

#Examine effects of larger effect size on transformation to Fisher's z
transform_d_to_r(c(0, 0.1, 1, 1.1, 2, 2.1), n1 = 100, n2 = 100, fisher = TRUE) #sourced function


```



# Supplement B


```{r Supplement-B-table}
#Load simulation results (power/type 1 error for all effects)
dens <- readRDS("../data/power_simulation_results.RDS")
names(dens) <-  sort(unique(dat$effect)) #names were alphabetized upon splitting in simulation so must sort


#Summary of results. These are incorporated into the main table in the paper, see tables.rmd
zero <- dens %>% 
  bind_rows(.id = "effect") %>% 
  group_by(effect, tau_index) %>% 
  summarize(power = mean(Qp <= 0.05)) %>% #Estimate power/type 1 error for each tau level and effect
  ungroup() %>% 
  tidyr::spread(key = tau_index, value = power) %>% #prep for table
  rename(Zero = '1', Small = '2', Medium = '3', Large = '4', Effect = effect)

##Medium effect size results
dens2 <- readRDS("../data/supplementB_power_simulation_results.RDS") 
names(dens2) <-  sort(unique(dat$effect))

#Summary of results.
medium <- dens2 %>% 
  bind_rows(.id = "effect") %>% 
  group_by(effect, tau_index) %>% 
  summarize(power = mean(Qp <= 0.05)) %>% #Estimate power/type 1 error for each tau level and effect
  ungroup() %>% 
  tidyr::spread(key = tau_index, value = power) %>% #prep for table
  rename(Zero = '1', Small = '2', Medium = '3', Large = '4') %>% 
  select(-effect)

##combine for table

comparison <- cbind(zero, medium)
```

Sensitivity analysis assuming a medium true effect size rather than zero true effect size

In our main results we simulated data to estimate type I error and power using an average true effect size equal to zero. As explained in the methods section this is unlikely to matter as our interest lies in heterogeneity. However, as a sensitivity analysis, in Supplement B we also estimated type I error and power, but generated with an average 'medium' true effect size as defined by Cohen (1988).

Estimated type I error and power for zero/small/medium/large heterogeneity when simulated with a true effect size of zero vs. medium are shown for each effect in Table SB1. In both cases type I error is approximately nominal, as compared to the expected 5% error rate. With a true effect size of zero, average power was `r 100*round(mean(zero$Small), digits = 2)`%/`r 100*round(mean(zero$Medium), digits = 2)`%/`r 100*round(mean(zero$Large), digits = 2)`% for small/medium/large heterogeneity, respectively. The corresponding power with a true medium effect size was also `r 100*round(mean(zero$Small), digits = 2)`%/ `r 100*round(mean(zero$Medium), digits = 2)`%/`r 100*round(mean(zero$Large), digits = 2)`%, respectively. To conclude, changing true effect size in our simulations from zero to medium had little to no impact on estimated type I error and power.

## Table S1B

_Type I error and power to detect four heterogeneity levels under two true effect sizes_

```{r table-S1B}
knitr::kable(comparison, digits = 2, longtable = TRUE, booktabs = TRUE) %>% 
  add_header_above(c(" " = 1, "True effect size zero" = 4, "True effect size medium" = 4)) %>% 
  add_header_above(c(" " = 1, "Type I error rate and power for different heterogeneity levels" = 8))
```

**Note.** Column headers indicate the degree of simulated heterogeneity where Zero = simulated type 1 error, and the other headers represent simulated power under small/medium/large heterogeneity ($I^2$ = 25/50/75%) respectively. Medium effect size is as defined by Cohen (1988). 

# Supplement C

```{r preprocessing-supp-C}

SMDs_raw <- dat %>% filter(outcomes1_2 == "mean _ SD") %>% 
  mutate(wi = compute_precision(SD1 = outcome_t2, SD2 = outcome_c2, n1 = ntreatment, n2 = ncontrol)) #compute_precision function is sourced

average_within <- SMDs_raw %>% #these values we now wish to correlate with meta-analytic results
  group_by(effect) %>% 
  summarize(s2 = sum(wi) * (n()-1) / (sum(wi)^2 - sum(wi^2))) %>% #Average within study variance; equation 9. Higgins and Thompson (2002). n() = k [number of studies in a meta-analysis]
  ungroup()


#Raw mean differences to SMD
MD_standardized <- dat %>% 
  filter(outcomes1_2 == "mean _ SD") %>% #Note, drops Mean _ SE studies (two) since no method in metafor to convert into standardized mean differences
  split(.$effect) %>% 
  map_dfr(MD_fit, .id = "effect") #MD_fit function is sourced

tau_per_type <- MD_standardized %>% 
  left_join(average_within) %>%
  mutate(sigma = sqrt(s2),
         eff_size = abs(eff_size),
         tau = sqrt(tau2)) #needed for bootfitter function below to work but not used


#As above but dropping the 4 largest effect sizes (Anchoring effects)----
without_anchoring <- tau_per_type %>% 
  filter(!grepl("Anchoring", effect))


corr_data <- tau_per_type %>%
  select(s2, eff_size, s_I2, H2) %>% 
  rename("$\\hat{\\mu}$" = "eff_size", "$I^2$" = "s_I2", "$H^2$" = "H2", "$s^2$" = s2)


corr_data_no_anchoring <- without_anchoring %>%
  select(s2, eff_size, s_I2, H2) %>% 
  rename("$\\hat{\\mu}$" = "eff_size", "$I^2$" = "s_I2", "$H^2$" = "H2", "$s^2$" = s2)


```

## Table S1C. 

```{r table-S1C}

cors <- round(cor(corr_data), digits = 2)
cors[upper.tri(cors)] <- "" #make upper triangle empty in correlation matrix

knitr::kable(cors, booktabs = TRUE, escape = FALSE)
```

**Note:** The Pearson correlations from 40 meta-analyses estimated with the random effects model and restricted maximum likelihood. $s^2$ = "typical" within studies variance (Higgins and Thompson, 2002, equation 9), $\hat{\mu}$ = average absolute effect size, $I^2$ = $\hat{\tau}^2$ / $(\hat{\tau}^2 + s^2)$ , $H^2$ = $Q/(K-1)$ where $Q$ is the Q-statistic and $K$ is the number of studies in a meta-analysis. This expression for $H^2$ is strictly only correct when using the DerSimonian-Laird estimator, see main manuscript for why we use it nontheless. In all 40 meta-analyses effect sizes were measured as mean or standardized mean differences. Effects reported as mean differences were standardized for the meta-analyses.


## Table S2C. 

```{r table-S2C-no-anchoring-SMD}
cors_anch <- round(cor(corr_data_no_anchoring), digits = 2)
cors_anch[upper.tri(cors_anch)] <- "" #make upper triangle empty in correlation matrix

knitr::kable(cors_anch, booktabs = TRUE, escape = FALSE)

```

**Note:** The Pearson correlations from 36 meta-analyses estimated with the random effects model and restricted maximum likelihood. The sample of effects is identical to Table S1C but with 4 Anchoring effects excluded. $s^2$ = "typical" within studies variance (Higgins and Thompson, 2002, equation 9), $\hat{\mu}$ = average absolute effect size, $I^2$ = $\hat{\tau}^2$ / $(\hat{\tau}^2 + s^2)$ , $H^2$ = $Q/(K-1)$ where $Q$ is the Q-statistic and $K$ is the number of studies in a meta-analysis. This expression for $H^2$ is strictly only correct when using the DerSimonian-Laird estimator, see main manuscript for why we use it nontheless. In all 40 meta-analyses effect sizes were measured as mean or standardized mean differences. Effects reported as mean differences were standardized for the meta-analyses.